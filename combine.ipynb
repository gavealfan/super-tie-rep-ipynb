{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             AuthorID                  PaperID  \\\n",
      "0               1968             [1527357417]   \n",
      "1               3809              [658362731]   \n",
      "2               4242              [647400699]   \n",
      "3               7762              [623108090]   \n",
      "4               7829  [328324571, 1521076585]   \n",
      "...              ...                      ...   \n",
      "15917377  3217809992              [573048486]   \n",
      "15917378  3217810022             [1504204380]   \n",
      "15917379  3217810146             [1146972988]   \n",
      "15917380  3217810245             [1595719892]   \n",
      "15917381  3217810830             [1507910090]   \n",
      "\n",
      "                                             FieldID  \n",
      "0                   [144024400, 15708023, 199539241]  \n",
      "1                              [127413603, 42475967]  \n",
      "2                              [142362112, 52119013]  \n",
      "3                                [17744445, 3116431]  \n",
      "4         [205649164, 166957645, 95457728, 15708023]  \n",
      "...                                              ...  \n",
      "15917377                       [142362112, 27206212]  \n",
      "15917378                       [71924100, 159110408]  \n",
      "15917379            [71924100, 164705383, 126322002]  \n",
      "15917380                       [142362112, 52119013]  \n",
      "15917381            [71924100, 154945302, 204321447]  \n",
      "\n",
      "[15917382 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('grouped_exploded_part_1.csv')\n",
    "print(df1.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             AuthorID                  PaperID  \\\n",
      "0               1968             [1527357417]   \n",
      "1               3809              [658362731]   \n",
      "2               4242              [647400699]   \n",
      "3               7762              [623108090]   \n",
      "4               7829  [328324571, 1521076585]   \n",
      "...              ...                      ...   \n",
      "15917377  3217809992              [573048486]   \n",
      "15917378  3217810022             [1504204380]   \n",
      "15917379  3217810146             [1146972988]   \n",
      "15917380  3217810245             [1595719892]   \n",
      "15917381  3217810830             [1507910090]   \n",
      "\n",
      "                                             FieldID  \n",
      "0                   [144024400, 15708023, 199539241]  \n",
      "1                              [127413603, 42475967]  \n",
      "2                              [142362112, 52119013]  \n",
      "3                                [17744445, 3116431]  \n",
      "4         [205649164, 166957645, 95457728, 15708023]  \n",
      "...                                              ...  \n",
      "15917377                       [142362112, 27206212]  \n",
      "15917378                       [71924100, 159110408]  \n",
      "15917379            [71924100, 164705383, 126322002]  \n",
      "15917380                       [142362112, 52119013]  \n",
      "15917381            [71924100, 154945302, 204321447]  \n",
      "\n",
      "[15917382 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('grouped_exploded_part_1.csv')\n",
    "print(df2.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(csv1, csv2):\n",
    "  df1 = pd.read_csv(f'{csv1}.csv')\n",
    "  df2 = pd.read_csv(f'{csv2}.csv')\n",
    "  combined_df = pd.concat([df1, df2])\n",
    "  combined_df['FieldID'] = combined_df['FieldID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "  combined_df['PaperID'] = combined_df['PaperID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "  grouped_df = combined_df.groupby('AuthorID').agg({\n",
    "    'PaperID': lambda x: list(item for sublist in x for item in sublist),\n",
    "    'FieldID': lambda x: list(item for sublist in x for item in sublist)\n",
    "  }).reset_index()\n",
    "  grouped_df.to_csv(f'combined_{csv1}_{csv2}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['grouped_exploded_part_1', 'grouped_exploded_part_3', 'grouped_exploded_part_5', \n",
    "         'grouped_exploded_part_7', 'grouped_exploded_part_9']\n",
    "list2 = ['grouped_exploded_part_2', 'grouped_exploded_part_4', 'grouped_exploded_part_6', \n",
    "         'grouped_exploded_part_8', 'grouped_exploded_part_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_grouped_exploded_part_1_grouped_exploded_part_2.csv is completed\n",
      "combined_grouped_exploded_part_3_grouped_exploded_part_4.csv is completed\n",
      "combined_grouped_exploded_part_5_grouped_exploded_part_6.csv is completed\n",
      "combined_grouped_exploded_part_7_grouped_exploded_part_8.csv is completed\n",
      "combined_grouped_exploded_part_9_grouped_exploded_part_10.csv is completed\n"
     ]
    }
   ],
   "source": [
    "for csv1, csv2 in zip(list1, list2):\n",
    "  combine(csv1, csv2)\n",
    "  print(f'combined_{csv1}_{csv2}.csv is completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             AuthorID                   PaperID  \\\n",
      "0                978  [1944453522, 1978468375]   \n",
      "1               1968              [1527357417]   \n",
      "2               2722  [1980984980, 1986503534]   \n",
      "3               2797              [1990420345]   \n",
      "4               3345              [1980977210]   \n",
      "...              ...                       ...   \n",
      "29130486  3217810625              [1974305505]   \n",
      "29130487  3217810666              [1898170596]   \n",
      "29130488  3217810715              [1995809114]   \n",
      "29130489  3217810830              [1507910090]   \n",
      "29130490  3217810934              [1967954122]   \n",
      "\n",
      "                                                    FieldID  \n",
      "0               [144024400, 15708023, 144024400, 107993555]  \n",
      "1                          [144024400, 15708023, 199539241]  \n",
      "2         [144133560, 42475967, 162853370, 17744445, 311...  \n",
      "3                                     [15744967, 118552586]  \n",
      "4                            [15744967, 70410870, 77805123]  \n",
      "...                                                     ...  \n",
      "29130486                      [71924100, 1862650, 99508421]  \n",
      "29130487                             [127413603, 133731056]  \n",
      "29130488                    [71924100, 90924648, 126322002]  \n",
      "29130489                   [71924100, 154945302, 204321447]  \n",
      "29130490                               [33923547, 11413529]  \n",
      "\n",
      "[29130491 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "combined_df1_df2 = pd.read_csv('combined_grouped_exploded_part_1_grouped_exploded_part_2.csv')\n",
    "print(combined_df1_df2.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df1, df2])\n",
    "\n",
    "# Group by AuthorID and aggregate PaperID and FieldID into lists\n",
    "grouped_df = combined_df.groupby('AuthorID').agg({\n",
    "    'PaperID': lambda x: list(set(item for sublist in x for item in sublist)),\n",
    "    'FieldID': lambda x: list(set(item for sublist in x for item in sublist))\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## DO NOT RUN - WILL CRASH KERNEL\n",
    "df1 = pd.read_csv('combined_grouped_exploded_part_1_grouped_exploded_part_2.csv')\n",
    "df2 = pd.read_csv('combined_grouped_exploded_part_3_grouped_exploded_part_4.csv')\n",
    "df3 = pd.read_csv('combined_grouped_exploded_part_5_grouped_exploded_part_6.csv')\n",
    "df4 = pd.read_csv('combined_grouped_exploded_part_7_grouped_exploded_part_8.csv')\n",
    "df5 = pd.read_csv('combined_grouped_exploded_part_9_grouped_exploded_part_10.csv')\n",
    "combined_df = pd.concat([df1, df2, df3, df4, df5])\n",
    "combined_df['FieldID'] = combined_df['FieldID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "combined_df['PaperID'] = combined_df['PaperID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "grouped_df = combined_df.groupby('AuthorID').agg({\n",
    "    'PaperID': lambda x: list(item for sublist in x for item in sublist),\n",
    "    'FieldID': lambda x: list(item for sublist in x for item in sublist)\n",
    "  }).reset_index()\n",
    "grouped_df.to_csv(f'final_author_paper_field.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('combined_grouped_exploded_part_1_grouped_exploded_part_2.csv')\n",
    "df2 = pd.read_csv('combined_grouped_exploded_part_3_grouped_exploded_part_4.csv')\n",
    "combined_df = pd.concat([df1, df2])\n",
    "combined_df['FieldID'] = combined_df['FieldID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "combined_df['PaperID'] = combined_df['PaperID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "grouped_df = combined_df.groupby('AuthorID').agg({\n",
    "    'PaperID': lambda x: list(item for sublist in x for item in sublist),\n",
    "    'FieldID': lambda x: list(item for sublist in x for item in sublist)\n",
    "  }).reset_index()\n",
    "grouped_df.to_csv(f'final_author_paper_field_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('combined_grouped_exploded_part_5_grouped_exploded_part_6.csv')\n",
    "df4 = pd.read_csv('combined_grouped_exploded_part_7_grouped_exploded_part_8.csv')\n",
    "combined_df = pd.concat([df3, df4])\n",
    "combined_df['FieldID'] = combined_df['FieldID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "combined_df['PaperID'] = combined_df['PaperID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "grouped_df = combined_df.groupby('AuthorID').agg({\n",
    "    'PaperID': lambda x: list(item for sublist in x for item in sublist),\n",
    "    'FieldID': lambda x: list(item for sublist in x for item in sublist)\n",
    "  }).reset_index()\n",
    "grouped_df.to_csv(f'final_author_paper_field_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df12 = pd.read_csv('final_author_paper_field_1.csv')\n",
    "df34 = pd.read_csv('final_author_paper_field_2.csv')\n",
    "combined_df = pd.concat([df12, df34])\n",
    "combined_df['FieldID'] = combined_df['FieldID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "combined_df['PaperID'] = combined_df['PaperID'].apply(lambda x: ast.literal_eval(x) if x else [])\n",
    "grouped_df = combined_df.groupby('AuthorID').agg({\n",
    "    'PaperID': lambda x: list(item for sublist in x for item in sublist),\n",
    "    'FieldID': lambda x: list(item for sublist in x for item in sublist)\n",
    "  }).reset_index()\n",
    "grouped_df.to_csv(f'final_1.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
